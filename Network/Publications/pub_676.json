{
    "container_type": "Publication",
    "source": "AUTHOR_PUBLICATION_ENTRY",
    "bib": {
        "title": "Sparse linear concept discovery models",
        "pub_year": 2023,
        "citation": "Proceedings of the IEEE/CVF International Conference on Computer Vision \u2026, 2023",
        "author": "Konstantinos Panagiotis Panousis and Dino Ienco and Diego Marcos",
        "conference": "Proceedings of the IEEE/CVF International Conference on Computer Vision",
        "pages": "2767-2771",
        "abstract": "The recent mass adoption of DNNs, even in safety-critical scenarios, has shifted the focus of the research community towards the creation of inherently intrepretable models. Concept Bottleneck Models (CBMs) constitute a popular approach where hidden layers are tied to human understandable concepts allowing for investigation and correction of the network's decisions. However, CBMs usually suffer from:(i) performance degradation and (ii) lower interpretability than intended due to the sheer amount of concepts contributing to each decision. In this work, we propose a simple yet highly intuitive interpretable framework based on Contrastive Language Image models and a single sparse linear layer. In stark contrast to related approaches, the sparsity in our framework is achieved via principled Bayesian arguments by inferring concept presence via a data-driven Bernoulli distribution. As we experimentally show, our framework not only outperforms recent CBM approaches accuracy-wise, but it also yields high per example concept sparsity, facilitating the individual investigation of the emerging concepts."
    },
    "filled": true,
    "author_pub_id": "IUqydU0AAAAJ:kRWSkSYxWN8C",
    "num_citations": 4,
    "citedby_url": "/scholar?hl=en&cites=2682521482358256770",
    "cites_id": [
        "2682521482358256770"
    ],
    "pub_url": "https://openaccess.thecvf.com/content/ICCV2023W/CLVL/html/Panousis_Sparse_Linear_Concept_Discovery_Models_ICCVW_2023_paper.html",
    "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:gnRRWhM7OiUJ:scholar.google.com/",
    "cites_per_year": {
        "2023": 3,
        "2024": 1
    }
}